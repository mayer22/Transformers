{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17001856-c8a4-49aa-944b-91075eab6145",
   "metadata": {},
   "source": [
    "# T5 Summarization Example\n",
    "\n",
    "_Developed from Hugging Face example_\n",
    "\n",
    "_https://huggingface.co/docs/transformers/tasks/summarization_\n",
    "\n",
    "This notebook helps you fine-tune a T5 model to a public dataset that has lengthy descriptions **(input)** and summaries **(labels/target)** for training.\n",
    "\n",
    "You can then run inference using the fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdcbda-dec9-4f40-9406-8f4279596e16",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8e3c80-12c6-4e1e-99ae-400383e66672",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873fb55-ef98-4b91-99a0-56e4792e8c86",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f5a0a-09f4-4be8-871a-a55d660182e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e577f27c2eb14e8284eefc72d918c2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayer2\\AppData\\Local\\anaconda3\\envs\\envDahlgren\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mayer2\\.cache\\huggingface\\hub\\datasets--billsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9325c05161f46599921fb683e863dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/91.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aec1a0-0712-4ea3-b137-dc01362c97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeefd04-23ff-4e29-87d2-a1611afd64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data\n",
    "billsum[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce06864-e3de-4267-b096-22388ae57b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "checkpoint = \"google-t5/t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb071b9c-a12f-44e7-8bd8-3bf6136467b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to preprocess\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de518c-9d19-431f-8a82-339341e4baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess/tokenize\n",
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b374e9-7418-41ff-a401-1f556819468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# Create a batch of samples\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afec7a9-cf96-400d-9da1-0b54cd04ac7c",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d9fbe-4072-404f-9a31-860ff7e6e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571ca09-076f-4907-af78-6debcc897c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160b30a-cebb-4432-92e5-0c7a7bc9fb4d",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a64f17-6724-460f-8eae-9ea57a460be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49540930-5172-4235-aa19-52749ccbd0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up params\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True, #change to bf16=True for XPU\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279840fe-e99e-4f80-b7c4-ecf0164f91f2",
   "metadata": {},
   "source": [
    "## Use model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9afb90-5d34-4fa2-b178-bc911474d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test sample\n",
    "text = \"summarize: The Inflation Reduction Act lowers prescription drug costs, health care costs, and energy costs. It's the most aggressive action on tackling the climate crisis in American history, which will lift up American workers and create good-paying, union jobs across the country. It'll lower the deficit and ask the ultra-wealthy and corporations to pay their fair share. And no one making under $400,000 per year will pay a penny more in taxes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fd522-4fd6-4ec1-9a1d-69e181ed251c",
   "metadata": {},
   "source": [
    "#### Pipeline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044f89-f4a5-41cf-b790-9267a905d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"./results\")\n",
    "summarizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f32a9-c9da-479c-aabd-23d1c5a75fbc",
   "metadata": {},
   "source": [
    "#### Manual Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2a862-f741-4d41-87ff-0baf986f04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenize and format\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./results\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92232b2b-2839-4859-aeac-2c88883ecddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# Generate tokens\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./results\")\n",
    "outputs = model.generate(inputs, max_new_tokens=100, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7769747-1392-44d5-ab82-0a5c67563eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to text\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDahlgren",
   "language": "python",
   "name": "envdahlgren"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
