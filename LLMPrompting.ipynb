{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSLSF2ayMGel"
   },
   "source": [
    "# **Interacting with an LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xT1NHYa51Cn"
   },
   "source": [
    "## **Step 1 - Installing LLM and prerequisities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXzNKJiYQ1-3"
   },
   "source": [
    "\n",
    "**In this tutorial, we will work with Gemma 3:4b which is a local LLM that you can install on your machine. We will access it using Ollama.**\n",
    "\n",
    "Gemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal—processing text and images—and feature a 128K context window with support for over 140 languages. Available in 270M, 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices.\n",
    "\n",
    "The **first step** is to install Ollama and Gemma3:4b on your machine\n",
    "* Download Ollama for Windows from https://ollama.com/download/windows\n",
    "* Install Ollama\n",
    "* Installation of gemma3:4b\n",
    "    * Open Terminal\n",
    "    * Execute the command `- ollama --version`\n",
    "    * To install Gemma3:4B `- ollama pull gemma3:4b`\n",
    "    * Check the version of the LLMs installed locally using `- ollama list`\n",
    "\n",
    "The **second step** is to install all the required software packages and dependencies.\n",
    "\n",
    "* `openai==1.102.0`: To interface with OpenAI’s LLM.\n",
    "* `python-dotenv`: This library is used to load environment variables from a `.env` file. This helps keep sensitive information, like API keys, secure.\n",
    "* `datasets`: The datasets library provides easy access to a wide variety of datasets commonly used for natural language processing tasks.\n",
    "* `evaluate`: A collection of evaluation metrics for natural language processing tasks.\n",
    "\n",
    "**Note:** Make sure you have a `.env` file in your working directory with your OpenAI API key stored as `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djBYyhXAiaxG",
    "outputId": "f9023d36-6f1e-4ae8-9166-116778ffc5ad"
   },
   "outputs": [],
   "source": [
    "# %pip install openai==1.102.0 python-dotenv datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubym_EoQnw_o"
   },
   "source": [
    "Next, **we will import the necessary libraries** that will be used for various activities such as data processing, API interaction, and environment management tasks.\n",
    "\n",
    "\n",
    "- `os`: Provides functions to interact with the operating system, such as accessing environment variables and file paths.\n",
    "- `openai`: A library to interact with OpenAI's API for utilizing their language models.\n",
    "- `dotenv`: Used for loading environment variables from a `.env` file, which helps in managing sensitive information securely.\n",
    "- `datasets`: The datasets library, part of Hugging Face, provides tools to access and manage large-scale datasets and metrics for NLP and other machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuzJpszTYLnt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaIrQ9D96IvR"
   },
   "source": [
    "## **Step 2 - Loading LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnpxG-oeiu9I"
   },
   "source": [
    "<!-- The next step is to establish a connection with `GPT3.5 Turbo` using the **API key**.\n",
    "\n",
    "\n",
    "1. **Learn More About Setting Up an API Key for OpenAI/ChatGPT**:\n",
    "   - Visit the following link to get detailed information on how to set up an API key: [ChatGPT API Key Setup Guide](https://www.merge.dev/blog/chatgpt-api-key).\n",
    "\n",
    "2. **Create an Account and Generate an API Key**:\n",
    "   - To create an account and generate an API key, follow these steps:\n",
    "     - Go to the OpenAI platform: [OpenAI Platform](https://platform.openai.com).\n",
    "     - Sign up for a new account or log in if you already have one.\n",
    "     - Navigate to the API section.\n",
    "     - Generate a new API key and save it securely, as you will need it for API calls in this notebook.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Once you have successfully **generated an API key**,\n",
    "\n",
    "  - Create an `apikey.env.txt` file on your desktop and save your OpenAI API key.  The contents of the file will look like:\n",
    "      ```bash\n",
    "      APIKEY='YOURAPIKEY'\n",
    "      ```\n",
    "  - Provide the path to your API key file in the next cell. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AWZKrw1mn69"
   },
   "source": [
    "**Establishing connection with LLM through API key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3U2Aw8mSZG6i"
   },
   "outputs": [],
   "source": [
    "# If using an open-source model load API key from environment file\n",
    "# load_dotenv(dotenv_path=\"../apikey.env.txt\")  # replace the \"file path\" with the location of your API key file\n",
    "\n",
    "# APIKEY = os.getenv(\"APIKEY\")\n",
    "# openai.api_key = APIKEY\n",
    "\n",
    "# For a local model identify the location of the model and provide an api key if necessary\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",  # Local Ollama API\n",
    "    api_key=\"ollama\"                       # Dummy key\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3r4Q3SfjKGI"
   },
   "source": [
    "**Let us run a simple inference on LLM**\n",
    "\n",
    "Once the connection is established with the LLM, interact and make an inference using prompts. On receiving the user input, referred to as `prompt`, the LLM will print its output, otherwise known as `response`.\n",
    "\n",
    "\n",
    "The following code snippet demonstrates a simple interaction with the LLM.\n",
    "\n",
    "\n",
    "- Step 1: The `System` variable provides instructions to the LLM, guiding its behavior. This example instructs the LLM to provide honest answers and avoid any extra information.\n",
    "\n",
    "- Step 2: The `user` variable contains the question (user query to the LLM). In this case, \"What are the capabilities of an LLM?\"\n",
    "\n",
    "- Step 3: `Interact` with the LLM using the openai.ChatCompletion.create(), where we pass the system + user query (i.e., `prompt`).\n",
    "\n",
    "- Step 4: `Response` - The \"content\" variable captures the LLM's response, and the subsequent print statements display both the \"question\" and the model's \"response\".\n",
    "\n",
    "Additional information about prompting is provided in Step 4.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOJ-5m64jXFB",
    "outputId": "8145e8d7-4407-4ce1-b725-180fe471a423"
   },
   "outputs": [],
   "source": [
    "system = {'role': 'system', 'content': 'You are asked a question. Answer the question honestly. Avoid any elaboration.'}\n",
    "user = {'role': 'user', 'content': 'How is the weather in Virginia?'}\n",
    "\n",
    "\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[system, user],\n",
    "#     max_tokens=500\n",
    "# )\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oPUpfXt8YQF"
   },
   "source": [
    "## **Step 3 - Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0jP0AabNipe"
   },
   "source": [
    "\n",
    "\n",
    "**Interactions with LLMs**\n",
    "\n",
    "A prompt is a set of instructions provided as input to a LLM, guiding its response generation (LLM’s output). Prompts specify the desired behavior, output type, and constraints for the LLM to consider while generating a response.\n",
    "\n",
    "From a testing perspective, this presents a significant contrast to traditional software system testing, where the tester provides an input, and the system generates an output. Conversely, with LLMs, the structure and content of the prompt considerably affect the quality and relevance of the generated response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXVZh5Eu_936"
   },
   "source": [
    "### **Inferencing using a pre-trained LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNnVghjlnQ7x"
   },
   "source": [
    "**Prompt**\n",
    "\n",
    "A prompt in an LLM like ChatGPT is split up into multiple messages.  Each message  is either a user role, a system role, or an assistant role.\n",
    "\n",
    "* User role: User's query\n",
    "* System role: Instructions on how the model should behave or respond\n",
    "* Assistant role: Provides a method for giving examples of what a response should look like.  We will come back to this one in a later example\n",
    "\n",
    "Creating effective prompts is crucial for better engagement with the LLM. In other words, how the prompt is constructed affects the model evaluation.\n",
    "\n",
    "Unlike traditional T&E, which prioritizes generating realistic test inputs, for LLMs, it is important to create effective prompts that combine the test scenario (user input) with other contextual information relevant for the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwFMnvv04BVu"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Basic example - inferencing with the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkksNYWWatQi",
    "outputId": "6194efde-4534-4119-b2cd-a9b2a3172486"
   },
   "outputs": [],
   "source": [
    "system = {'role': 'system', 'content': 'You are asked a question. Answer the question honestly. Avoid any elaboration.'}\n",
    "user = {'role': 'user', 'content': 'What do you think about the weather in Virginia?'}\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49lKX9EEASai"
   },
   "source": [
    "**LLM outputs are sensitive to prompts**\n",
    "\n",
    "The instructions given in the system role can affect the output as much as the user role portion of the prompt.  The example below demonstrates how the behavior of LLM is influenced by different system instructions, even though the user's input remains the same.\n",
    "\n",
    "- In the first scenario, the system prompt asks the LLM to answer honestly, without assuming any role or any specific expertise.\n",
    "- In the second scenario, the system prompt instructs the LLM to take the role of a weather expert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgmKSEWV_3Py",
    "outputId": "27dfa81c-102e-47e3-ef0d-6d7eff8d29ba"
   },
   "outputs": [],
   "source": [
    "system = {'role': 'system', 'content': 'You are asked a question. Answer the question honestly.'}\n",
    "user = {'role': 'user', 'content': 'What do you think about the weather in Virginia?'}\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o13Nc3510Y4h",
    "outputId": "e1e724c2-8ca7-4309-9f6f-876fe8dcb974"
   },
   "outputs": [],
   "source": [
    "system = {'role': 'system', 'content': 'You are a weather expert. Answer the question.'}\n",
    "user = {'role': 'user', 'content': 'What do you think about the weather in Virginia?'}\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hxc-MKhgCWV2"
   },
   "source": [
    "### **Prompting Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGa3y2lkPHr6"
   },
   "source": [
    "**Prompting strategies** are techniques used to guide language models in generating desired responses.\n",
    "\n",
    "We will briefly introduce three common strategies:\n",
    "\n",
    "- **Zero-Shot Prompting**: Involves providing no prior examples to the model.\n",
    "- **Few-Shot Prompting**: Involves providing a few examples to help the model understand the prompt/task.\n",
    "- **Chain-of-Thought (COT) Prompting**: Involves breaking down complex tasks into simpler steps to help the model understand the prompt/task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vMWarugCaYL"
   },
   "source": [
    "#### **Zero-shot prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9KJIvjDULA2"
   },
   "source": [
    "In this prompt we will use zero-shot prompting to simply ask about the weather in Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8TuAo6pCZEY",
    "outputId": "083f864e-1e13-4b33-bde4-6f093c49de10"
   },
   "outputs": [],
   "source": [
    "system = {'role': 'system', 'content': 'You are asked a question. Answer the question honestly. Avoid any elaboration.'}\n",
    "user = {'role': 'user', 'content': 'What do you think about the weather in Chicago?'}\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjVz6--aClRT"
   },
   "source": [
    "#### **Few-shot prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOwfpFBJSKnh"
   },
   "source": [
    "In few-shot prompting, the model (LLM) is provided with a few examples to help the LLM in understanding the task.  Here we use the assistant role message type to provide examples of what the output response should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47Yw1J5kCm4v",
    "outputId": "87498d11-1821-4fbf-dd0e-9bf8d01f5dde"
   },
   "outputs": [],
   "source": [
    "few_shot_examples = [\n",
    "    {'role': 'system', 'content': 'You are asked a question. Answer the question honestly. Avoid any elaboration.'},\n",
    "    {'role': 'user', 'content': 'What do you think about the weather in New York?'},\n",
    "    {'role': 'assistant', 'content': 'The weather in New York can be quite variable, with cold winters and hot summers.'},\n",
    "    {'role': 'user', 'content': 'What do you think about the weather in San Francisco?'},\n",
    "    {'role': 'assistant', 'content': 'San Francisco is known for its mild climate, but it can be foggy and windy.'},\n",
    "    {'role': 'user', 'content': 'What do you think about the weather in Chicago?'}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Oq781i3EXcn"
   },
   "source": [
    "#### **Chain-of-thought prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkELsI3uSNLk"
   },
   "source": [
    "Here we use CoT prompting to offer a 'thought process' that the LLM can follow to reach the answer we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyYDSti8EZ56",
    "outputId": "6e18c2cf-3a1f-4296-edae-d9c4fb1e37ee"
   },
   "outputs": [],
   "source": [
    "chain_of_thought_examples = [\n",
    "    {'role': 'system', 'content': 'You are asked a question. Answer the question step-by-step to explain your reasoning. Avoid any unnecessary elaboration.'},\n",
    "    {'role': 'user', 'content': 'What do you think about the weather in Chicago?'},\n",
    "    {'role': 'assistant', 'content': \"\"\"Let's think step-by-step:\n",
    "    1. Chicago is located in the Midwest region of the United States.\n",
    "    2. The city experiences all four seasons.\n",
    "    3. Winters in Chicago are typically cold, with snow and wind.\n",
    "    4. Summers can be hot and humid.\n",
    "    5. Spring and fall are usually mild and pleasant.\n",
    "    Therefore, the weather in Chicago varies significantly with each season, having cold winters and hot summers.\"\"\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    \n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print('User Query to the Model:  \\n' + user['content'])\n",
    "print('\\nResponse from the Model: \\n' + content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZrPwF3JtpqA"
   },
   "source": [
    "# **Parameters and their impact on generation capabilities of an LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYMWE59spulE"
   },
   "source": [
    "**LLM outputs** are sensitive to input parameters.\n",
    "\n",
    "Input parameters to LLMs can be tweaked to control/influence the behavior of LLMs. Widely used input parameters that have a direct impact on the output are presented here.\n",
    "\n",
    "*   Temperature\n",
    "*   Top_P\n",
    "*   Token size (Maximum Tokens)\n",
    "*   Repeat penalty\n",
    "*   Frequency penalty\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAjXewSwBjqg"
   },
   "source": [
    "## Temperature parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwvyfGDwBqo4"
   },
   "source": [
    "**Temperature**: One of the key parameters in LLMs, temperature controls the randomness of the generated output.\n",
    "\n",
    "Typically, the temperature value ranges from 0 to 1. A value of 0 (or closer to 0) results in deterministic outcomes, while a value closer to 1 leads to higher variability and randomness in the responses.  In simpler terms, this parameter can be viewed as influencing how 'creative' the LLM can be.\n",
    "\n",
    "**In Gemma , the value of temperature ranges from 0.0 to 1.0**\n",
    "\n",
    "\n",
    "The following example will demonstrate the effect of temperature on an LLM's response -- Given the same input, it shows how different **temperature** settings lead to different outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOr_xRjzBZ75"
   },
   "outputs": [],
   "source": [
    "def GetModelResponse(system_content, user_content, temp):\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gemma3:4b\",\n",
    "    messages=[system, user],\n",
    "    temperature = temp\n",
    "    \n",
    ")\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZWSs3VEHjWD",
    "outputId": "570f0073-4e08-4f2e-e9e1-5ea74ff54fc1"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"What do you think about the weather in Chicago?\"\n",
    "temp = 1.0\n",
    "\n",
    "for x in range(10):\n",
    "    temp = x / 10\n",
    "    modelResponse = GetModelResponse(system_content, user_content, temp)\n",
    "    print(\"\\n-------------------------\")\n",
    "    print(\"Temperature = \" + str(temp))\n",
    "    print(\"-------------------------\\n\")\n",
    "    print(\"Input:  \" + user_content + \"\\nResponse = \" + modelResponse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVNCxk59qLKq"
   },
   "source": [
    "## Top-p parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-xuUz_BP__9"
   },
   "source": [
    "Top-p, also called as nucleus sampling, is a parameter that controls the diversity of the LLM's output.\n",
    "\n",
    "\n",
    "When the LLM is generating a response (output), it has many potential words to choose from, Top-p limits the selection to words (tokens) whose cumulative probability reaches or exceeds the specified top-p value.\n",
    "\n",
    "Top-p ranges from 0.0 to 1.0, with 0 being the most conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cej-MdLBEeqn"
   },
   "outputs": [],
   "source": [
    "def GetModelResponse_topP(system_content, user_content, p_value):\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma3:4b\",\n",
    "        top_p=p_value,\n",
    "        messages=[system, user],\n",
    "\n",
    ")\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jttVIiBkyNd7",
    "outputId": "1819470f-487d-494e-d280-caf8976db3d7"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"What do you think about the weather in Chicago?\"\n",
    "\n",
    "for x in range(10):\n",
    "    temp = x / 10\n",
    "    modelResponse = GetModelResponse_topP(system_content, user_content, temp)\n",
    "    print(\"\\n-------------------------\")\n",
    "    print(\"top-P = \" + str(temp))\n",
    "    print(\"-------------------------\\n\")\n",
    "    print(\"Input:  \" + user_content + \"\\nResponse = \" + modelResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwokz6XBPn09"
   },
   "source": [
    "\n",
    "Top-k is a sampling parameter, when LLM is generating a response,the Top-k parameter limits the LLM to select the top \"k\" most likely words based on their assigned probabilities.\n",
    "\n",
    "\n",
    "Note that, Top-p and Top-k are sampling parameters. However, they serve a different purpose.\n",
    "* Top-p aims to provide a balance between diversity and quality in the generated text by considering a set of words until a cumulative probability threshold is obtained. Thus, well suited for creative tasks like story telling\n",
    "* Top-k restricts the selection to only the top \"k\" most likely words, regardless of their cumulative probability. Thus, well suited for tasks that requires higher accuracy and determinitic outcomes. Example, Q&A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoidOkx05keo"
   },
   "source": [
    "## Token Size (Max tokens parameter)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1JfKRC2QqWe"
   },
   "source": [
    "The max_tokens parameter allows you to limit the length of the generated response.\n",
    "\n",
    "In other words, it refers to the maximum number of tokens that can be generated in a response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c9E-azxx0b3"
   },
   "outputs": [],
   "source": [
    "def GetModelResponse_maxTokens(system_content, user_content, maximumTokens):\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma3:4b\",\n",
    "        messages=[system, user],\n",
    "        max_tokens=maximumTokens\n",
    "        # # Ollama-specific parameters go inside the `extra_body` or `options` dictionary\n",
    "        # extra_body={\n",
    "        #     \"options\": {\n",
    "        #         \"num_predict\": maximumTokens\n",
    "        #     }\n",
    "        # }\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTXu5CBCyf17",
    "outputId": "b5782a95-fe84-4f40-d41a-9c9826aa9c92"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC\"\n",
    "\n",
    "\n",
    "for x in range(1, 500, 50):\n",
    "    maximum_tokens = x\n",
    "    modelResponse = GetModelResponse_maxTokens(system_content, user_content, maximum_tokens)\n",
    "    print(\"\\n-------------------------\")\n",
    "    print(\"Maximum Tokens = \" + str(maximum_tokens))\n",
    "    print(\"-------------------------\\n\")\n",
    "    print(\"Input query to the model:  \" + str(user_content))\n",
    "    print(\"\\nResponses from the model\\n\")\n",
    "    print(modelResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNK5yDkyNnYt"
   },
   "source": [
    "## Presence penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1HMlzC8QHDe"
   },
   "source": [
    "The presence penalty parameter determines how the model penalizes new tokens based on their previous apperance in the text. The objective is not to sound repetitive, and it nudges the LLM to generate a variety of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxowAupBO2vS"
   },
   "outputs": [],
   "source": [
    "def GetModelResponse_presencePenalty(system_content, user_content, presencePenalty):\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma3:4b\",\n",
    "        presence_penalty=presencePenalty,\n",
    "        messages=[system, user],\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nb6lHyZpOEdj",
    "outputId": "41994d2a-9f18-4b38-e10b-a49cd5212659"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = -2  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWp8--iqAup9",
    "outputId": "af146f0d-a2bf-46b6-e8b4-5500c2dd442f"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = -1.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ehjJnpUPA06j",
    "outputId": "984d4d8d-c131-4127-b211-7f3c5d6f3f81"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = -1  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXtIKS2ZA6Lh",
    "outputId": "b8624547-1535-42e1-fe93-ffe566c867d8"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = -0.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XvL02stwBHtm",
    "outputId": "7fa3fe34-719a-49fb-e2d7-73e4325a514a"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = 0  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6A8JcHNBMPJ",
    "outputId": "cd059234-060d-45a8-ad30-c260e85d25c0"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = 0.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sI1z8qNiPUoS",
    "outputId": "bd669fea-35dd-4d12-f491-ffe9174ed687"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = 1.0  # [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WmE1jWFGPc2v",
    "outputId": "d60837dd-e183-49bf-e7d8-7aa15fbd8ae3"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = 1.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKQ0oLI_BZaR",
    "outputId": "da2b0d3c-9445-4b6c-d80f-ecab8c697771"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "presence_penalty = 2  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_presencePenalty(system_content, user_content, presence_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Presence Penalty = \" + str(presence_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4xIjjQEuX1P"
   },
   "source": [
    "## Frequency penalty parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUwxWKayQY1q"
   },
   "source": [
    "The frequency penalty parameter discourages the model from the frequent repetition of words or phrases, based on the existing frequency in the generated text. **The objective is to minimize the likelihood of repetitive tokens**\n",
    "\n",
    "From openAI's documentation - \"Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\"  This parameter is defined on the range of `[-2,2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSlvmGgXueR2"
   },
   "outputs": [],
   "source": [
    "def GetModelResponse_frequencyPenalty(system_content, user_content, frequencyPenalty):\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemma3:4b\",\n",
    "        frequency_penalty=frequencyPenalty,\n",
    "        messages=[system, user],\n",
    "        \n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31yQUYbkx_Dl",
    "outputId": "8e478269-e92c-49bc-a6d9-ae549be4ea2b"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = -2  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MqYXkxJM1hVh",
    "outputId": "b50446e0-a858-489c-f0a1-7aacf184e85f"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = -1.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OmfiKsZ1pdx",
    "outputId": "3afe5926-e04a-4090-aedc-f71713e1e002"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = -1  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RiKyHT5W1uOr",
    "outputId": "e61b3fb4-6644-42b9-e1e6-d753d335c24f"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = -0.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFw34HcA1y3B",
    "outputId": "451ac3da-62cb-47a7-92f0-7469f1fab0b9"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = 0  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WpyVu7Y14G-",
    "outputId": "761a751a-b42a-4ca9-ffe6-5421295bc6e3"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = 0.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6niGJeA18km",
    "outputId": "339b8362-de12-49ef-da82-0787310a3012"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = 1  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKkCKXT_2Kwa",
    "outputId": "b81c5ef3-5f78-4050-a1ea-e9350a7680a3"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = 1.5  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ALsk3hPU2agR",
    "outputId": "64d36056-45a6-4ed4-ac3c-4894127d0016"
   },
   "outputs": [],
   "source": [
    "system_content = \"You are asked a question. Answer the question honestly. \"\n",
    "user_content = \"Describe Washington DC in 20 different ways\"\n",
    "frequency_penalty = 2  # [-2 to 2] [impact on generative capabilities of LLM]\n",
    "\n",
    "modelResponse = GetModelResponse_frequencyPenalty(system_content, user_content, frequency_penalty)\n",
    "\n",
    "print(\"\\n-------------------------\")\n",
    "print(\"Frequency Penalty = \" + str(frequency_penalty))\n",
    "print(\"-------------------------\\n\")\n",
    "print(\"Input query to the model:  \" + str(user_content))\n",
    "print(\"\\nResponses from the model\\n\")\n",
    "print(modelResponse)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04c7b53b01144690943a54f3eb0f5c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b5b0ae9c06648149c3e1a611da3dc6f",
       "IPY_MODEL_b0a3ca8143fc40499224fa994bd2f126",
       "IPY_MODEL_07b0a7e38d4d48c5b6419b57ace7535a"
      ],
      "layout": "IPY_MODEL_8e05925a5f4748fba71b29b82914615e"
     }
    },
    "05db10074c6c4ebe9bf7a11e9a079cad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07b0a7e38d4d48c5b6419b57ace7535a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca6ce1c336b24fa899a93de3d6aa0103",
      "placeholder": "​",
      "style": "IPY_MODEL_5354d4569b4b470e85934ffdcc625e21",
      "value": " 3250/3250 [00:01&lt;00:00, 2656.14 examples/s]"
     }
    },
    "0ac091dba5dc4526afe8477205c49fb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b5b0ae9c06648149c3e1a611da3dc6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa7a391952e54ae6961dbbe85c1af8d1",
      "placeholder": "​",
      "style": "IPY_MODEL_cff1f184124748f5be41c862566974e4",
      "value": "Generating validation split: 100%"
     }
    },
    "0eea9e5f08744bca85aa353691c1970e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10ebf80ee63a493f9d54f2e3588df3d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13856767333f4c60a54e9c898313dd96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5156c5a86988472eb86150066f8c0ab9",
      "max": 9570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5172cb8d86aa481b8e772ea9d952d128",
      "value": 9570
     }
    },
    "18ecd4968e5c4e3caeaa228721141cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_656dce66b269463daf5c4f71b0f41e0d",
      "placeholder": "​",
      "style": "IPY_MODEL_56a625d9948d4ae29c7523e2d2a0d901",
      "value": "Downloading data: 100%"
     }
    },
    "19a5383daee5454fb9fd95642e5ef4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e54ad74eeae409aadc5eb9bb6328fc5",
      "placeholder": "​",
      "style": "IPY_MODEL_bcdc0aadff1947a9a17ac5366ae654b9",
      "value": " 12.3k/12.3k [00:00&lt;00:00, 409kB/s]"
     }
    },
    "1ab7759b6a9a4dedb9759713c9074e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21d6bc9cf2c24d638078211c1b8f5f27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21f7802f73d6484b8b53c1d150661293": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_507183f9a6934f58b2829a55bef08345",
      "placeholder": "​",
      "style": "IPY_MODEL_1ab7759b6a9a4dedb9759713c9074e6a",
      "value": "Generating train split: 100%"
     }
    },
    "335a522386c34816b8ddc4294e9f844e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c914cf64e9c42939e0cf2b442f0962d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c95bca16ad241e196e8a96533e2d01c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4949427ec7d443e2b138800bab2960f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5023bd7957634cfb99bbd6e3f010c808": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "507183f9a6934f58b2829a55bef08345": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50b3f6d502cf4ee0bdc8b7cbdb399ddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5156c5a86988472eb86150066f8c0ab9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5172cb8d86aa481b8e772ea9d952d128": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5354d4569b4b470e85934ffdcc625e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56a625d9948d4ae29c7523e2d2a0d901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59ccd89342ff48f6a48742c75e71489d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_21f7802f73d6484b8b53c1d150661293",
       "IPY_MODEL_d6bf7a9f1c154caa924425858c0615ce",
       "IPY_MODEL_94e0d0a4920e4a8aa2e1e87db9e99bdd"
      ],
      "layout": "IPY_MODEL_0eea9e5f08744bca85aa353691c1970e"
     }
    },
    "5f0c4e2bae52467a81e0eee372f298a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b2372eb7d9bf4b22b83bdd11b54382f6",
       "IPY_MODEL_13856767333f4c60a54e9c898313dd96",
       "IPY_MODEL_fe43a06a93504cefadcc961f5e2c49c5"
      ],
      "layout": "IPY_MODEL_a8279938f53241c9a6cee928c021456e"
     }
    },
    "61906de8bd594aa0a5f4eab0f6da8b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "656dce66b269463daf5c4f71b0f41e0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "659e2c0b4167430282c9e5c805b1bf65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bb56a5fabc0483ea8bc9b90e8d9de63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7245f34d01a64aa4b7378ccb6f86ebc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79dfe3b8f91e407a96516aae5dc3d09e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d42a8b6baf646e39a6e058a667a8cd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e54ad74eeae409aadc5eb9bb6328fc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80601881356d41adb4d706730b331c64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bb56a5fabc0483ea8bc9b90e8d9de63",
      "placeholder": "​",
      "style": "IPY_MODEL_a7840a41b1434035ac178613f7b980bb",
      "value": "Generating test split: 100%"
     }
    },
    "80ad557fc1844697a0e0013c6f3c2544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18ecd4968e5c4e3caeaa228721141cd0",
       "IPY_MODEL_f8530c3c6ff64d7b9d57d88c9ef40273",
       "IPY_MODEL_ea437604d70740bdb395b722dec8a63c"
      ],
      "layout": "IPY_MODEL_7d42a8b6baf646e39a6e058a667a8cd5"
     }
    },
    "81f933217a7040efa3a51334a49c609f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2f5f9855e504ef7ab467e37ccf151bd",
       "IPY_MODEL_ad3173a03d9c4496a52b2258438496d3",
       "IPY_MODEL_19a5383daee5454fb9fd95642e5ef4c7"
      ],
      "layout": "IPY_MODEL_5023bd7957634cfb99bbd6e3f010c808"
     }
    },
    "854ad635e28c4b1fa010b0703d768638": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cb41deb46b04c5893eaafedfb37fc6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8dc51f98f9d9416c80c6399b56f48c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e05925a5f4748fba71b29b82914615e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e9bec481f2742ebaddd67525f1dd76b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c95bca16ad241e196e8a96533e2d01c",
      "max": 3453,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7245f34d01a64aa4b7378ccb6f86ebc1",
      "value": 3453
     }
    },
    "94e0d0a4920e4a8aa2e1e87db9e99bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e18ca5fc33b74e7b9820d53b8ade8079",
      "placeholder": "​",
      "style": "IPY_MODEL_ebccb7617a22425c99b1aed19ffefb7c",
      "value": " 14041/14041 [00:03&lt;00:00, 3313.94 examples/s]"
     }
    },
    "96770ff6d8024e12a0a1a22c313089ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61906de8bd594aa0a5f4eab0f6da8b62",
      "placeholder": "​",
      "style": "IPY_MODEL_9a84e51c86824f179b3b3ce6a3d7224d",
      "value": " 3453/3453 [00:01&lt;00:00, 3439.18 examples/s]"
     }
    },
    "974deb3a2fff48409776faf2716db398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a84e51c86824f179b3b3ce6a3d7224d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a410050b622d430b96790d5471e19ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7840a41b1434035ac178613f7b980bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8279938f53241c9a6cee928c021456e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad3173a03d9c4496a52b2258438496d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a410050b622d430b96790d5471e19ab8",
      "max": 12330,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8cb41deb46b04c5893eaafedfb37fc6e",
      "value": 12330
     }
    },
    "aef983e0216f4baf805896de6830789f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0a3ca8143fc40499224fa994bd2f126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79dfe3b8f91e407a96516aae5dc3d09e",
      "max": 3250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8dc51f98f9d9416c80c6399b56f48c85",
      "value": 3250
     }
    },
    "b2372eb7d9bf4b22b83bdd11b54382f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21d6bc9cf2c24d638078211c1b8f5f27",
      "placeholder": "​",
      "style": "IPY_MODEL_4949427ec7d443e2b138800bab2960f2",
      "value": "conll2003.py: 100%"
     }
    },
    "bcdc0aadff1947a9a17ac5366ae654b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2f5f9855e504ef7ab467e37ccf151bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_335a522386c34816b8ddc4294e9f844e",
      "placeholder": "​",
      "style": "IPY_MODEL_50b3f6d502cf4ee0bdc8b7cbdb399ddc",
      "value": "README.md: 100%"
     }
    },
    "ca6ce1c336b24fa899a93de3d6aa0103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff1f184124748f5be41c862566974e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6bf7a9f1c154caa924425858c0615ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_854ad635e28c4b1fa010b0703d768638",
      "max": 14041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ac091dba5dc4526afe8477205c49fb0",
      "value": 14041
     }
    },
    "dc4283bf85d444c0acd1dfb6685a632c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80601881356d41adb4d706730b331c64",
       "IPY_MODEL_8e9bec481f2742ebaddd67525f1dd76b",
       "IPY_MODEL_96770ff6d8024e12a0a1a22c313089ac"
      ],
      "layout": "IPY_MODEL_e794f2b5548c48c5bc941164fd215c33"
     }
    },
    "e18ca5fc33b74e7b9820d53b8ade8079": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e794f2b5548c48c5bc941164fd215c33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea437604d70740bdb395b722dec8a63c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c914cf64e9c42939e0cf2b442f0962d",
      "placeholder": "​",
      "style": "IPY_MODEL_10ebf80ee63a493f9d54f2e3588df3d5",
      "value": " 983k/983k [00:00&lt;00:00, 2.91MB/s]"
     }
    },
    "ebccb7617a22425c99b1aed19ffefb7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8530c3c6ff64d7b9d57d88c9ef40273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_974deb3a2fff48409776faf2716db398",
      "max": 982975,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_659e2c0b4167430282c9e5c805b1bf65",
      "value": 982975
     }
    },
    "fa7a391952e54ae6961dbbe85c1af8d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe43a06a93504cefadcc961f5e2c49c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05db10074c6c4ebe9bf7a11e9a079cad",
      "placeholder": "​",
      "style": "IPY_MODEL_aef983e0216f4baf805896de6830789f",
      "value": " 9.57k/9.57k [00:00&lt;00:00, 272kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
