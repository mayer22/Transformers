{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0aa845b-bed6-4937-8f86-642870c5e423",
   "metadata": {},
   "source": [
    "# DistilBERT Text Classification Example\n",
    "\n",
    "_Developed from Hugging Face example_\n",
    "\n",
    "_https://huggingface.co/docs/transformers/tasks/sequence_classification_\n",
    "\n",
    "This notebook helps you fine-tune a DistilBERT model using a public IMDB of movie reviews **(input)** that are labeled positive and negative **(label/target)**.\n",
    "\n",
    "You can then run inference using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5265cd0c-ea37-4bf2-a1a1-90e8ff584377",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7487d8-e024-4710-abe1-36aeec70bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f18e79-d2d9-40c9-ba3c-e674fda75bb0",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11098a8f-d325-467a-aed7-24fd0786b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e65392-a798-4e03-ae3a-d2cd1ad87f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data\n",
    "imdb[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b2148-31a9-4f99-9fdc-eebfd611d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e816b5-ff7b-47f4-8d58-04368eccdc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to tokenize\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985dc07-47b0-42d5-ae98-48e3c075d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8438a0-a71b-4eb7-80cd-c46d21939c8d",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5551d444-a04c-4f34-9401-3b38642142cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c0030-89c2-41ac-bcc6-259dae7ac06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef49f4-27be-477a-a098-d0e069d61005",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa807cc-822d-4705-86d4-98673dcf1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map IDs to labels\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedce04-f7c4-4673-a00d-b9a9e9722da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad37a02-7dff-4843-bab7-db654d3f967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up params\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57de8a-8eac-471d-bd8b-3915bb1c7446",
   "metadata": {},
   "source": [
    "## Use model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d63ba-f7fe-47a7-91c9-1feb13ff76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test sample\n",
    "text = \"This was a masterpiece. Not completely faithful to the books, but enthralling from beginning to end. Might be my favorite of the three.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df51d7a-c5ad-48ce-b7d5-f4d10cb0a903",
   "metadata": {},
   "source": [
    "#### Pipeline Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3621d-b57e-41eb-aeaa-8ddd743a7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"./results\")\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b94b3-b5a2-414f-a0d1-3fd5bb9ae66f",
   "metadata": {},
   "source": [
    "#### Manual Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f935df6-4ce1-4c46-a71f-702ce74a870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenize and format\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stevhliu/my_awesome_model\")\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e043c1-9497-47d9-b3ef-d8b1317438f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envDahlgren",
   "language": "python",
   "name": "envdahlgren"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
